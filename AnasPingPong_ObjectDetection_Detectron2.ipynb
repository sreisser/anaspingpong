{"cells":[{"cell_type":"markdown","metadata":{"id":"DXr-V1AzypMd"},"source":["# Objection detection of ping-pong tables using Detectron 2 \n","\n","* Aim: Predict bounding box around ping-pong tables on map tiles.\n","* Input: Map tiles, width: 256 pixels, height 256 pixels\n","\n","* We'll train a ping-pong table object detection model from an existing model pre-trained on COCO dataset, available in detectron2's model zoo.\n","\n","* Candidate (Faster R-CNN) Pretrained Models:\n","\n","  * ResNet50_3x\n","  * ResNet101_3x\n","  * X101-FPN_3x "]},{"cell_type":"markdown","metadata":{"id":"Qb9qJiW2xLJs"},"source":["# Check to which GPU I'm assigned & make sure I am using high RAM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OaBAQjIZxJig"},"outputs":[],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UDipkbT5pL5O"},"outputs":[],"source":["# Check number of GPUs\n","from tensorflow.python.client import device_lib\n","\n","def get_available_gpus():\n","    local_device_protos = device_lib.list_local_devices()\n","    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n","\n","get_available_gpus()\n"]},{"cell_type":"markdown","metadata":{"id":"hm9GLkU-wqgI"},"source":["# Install detectron2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6RQn9i2wH5D"},"outputs":[],"source":["!pip install pyyaml==5.1\n","\n","import torch\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","# Install detectron2 that matches the above pytorch version\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n"]},{"cell_type":"markdown","metadata":{"id":"6LcrxO2mwyBK"},"source":["# Import libraries and utilities"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cioscdA8whnI"},"outputs":[],"source":["# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","import datetime\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"]},{"cell_type":"markdown","metadata":{"id":"MjkM4wzqxbRE"},"source":["# Train on a custom dataset"]},{"cell_type":"markdown","metadata":{"id":"kU3hi6YK2vSs"},"source":["## Mount to google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGPQiAnrVjAo"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"mi0jgDXA296C"},"source":["# Define ping-pong tables IDs for map tiles\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"z38xpcHn3OCG"},"source":["#### Get tile's X & Y coordinates of each map tile in  dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WvZMESvvMBaB"},"outputs":[],"source":["import glob\n","img_dir_json = \"/gdrive/MyDrive/AnasPingPong/data/detection/positive_w_bbox\"\n","\n","list_files_pos = [os.path.basename(x) for x in glob.glob(f\"{img_dir_json}/*.json\")]\n","print(f\"All tiles:  {len(list_files_pos)}\")\n","pos_tiles_x = [\n","    int(os.path.basename(f).split(\"_\")[1])\n","    for f in list_files_pos\n","]\n","\n","pos_tiles_y = [\n","    int(os.path.basename(f).split(\"_\")[2].split(\".\")[0])\n","    for f in list_files_pos\n","]"]},{"cell_type":"markdown","metadata":{"id":"WiRJb4423Zju"},"source":["#### Create ping-pong table's ID by clustering neighbouring map tiles\n","\n","* If the map tile's X & Y coordinates are close to previously defined tables => tile belongs to the same table => assign same ID"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxODn83mL7KI"},"outputs":[],"source":["ids = list()\n","id_unq_count = 0\n","\n","for i, (x, y) in enumerate(zip(pos_tiles_x, pos_tiles_y)):\n","    diff_prev_x = x - np.array(pos_tiles_x[:i]) # empty for first element\n","    diff_prev_y = y - np.array(pos_tiles_y[:i]) \n","    diffs_prev_xy = np.vstack((diff_prev_x, diff_prev_y)).T\n","    ppt_exists_mask = np.all(diffs_prev_xy>=-1, axis=1) & np.all(diffs_prev_xy<=1, axis=1)\n","    if any(ppt_exists_mask):\n","      i_true = [k for k, b in enumerate(ppt_exists_mask) if b]\n","      ids.append(ids[i_true[0]])\n","    else:\n","      ids.append(id_unq_count)\n","      id_unq_count += 1 \n","\n","print(f\"Unique tables: {len(set(ids))}\")"]},{"cell_type":"markdown","metadata":{"id":"xHY37L2p3viU"},"source":["# Create train & validation list of files\n","\n","* **Important note**: Make sure that all tiles with a given ID (ie corresponding to same table) are assigned to train or validation but not both, to avoid information leakage.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ApBx6qHiLqfg"},"outputs":[],"source":["SEED = 43\n","val_size_fraction = 0.2\n","n_pos_all = len(list_files_pos)\n","n_pos_val = round(n_pos_all * val_size_fraction)\n","indices_id = list(range(n_pos_all))\n","\n","diff_exp_vs_curr = 100 # initialize it high\n","\n","# Reshuffle if we end up with a lot more tables than wanted \n","while diff_exp_vs_curr > 10:\n","  # Create seed to be used for both POSITIVE and NEGATIVE dataset creation\n","  # SEED = random.randrange(sys.maxsize) \n","\n","  indices_id_shuffled = indices_id.copy()\n","  # random.shuffle(indices_id_shuffled)\n","  random.Random(SEED).shuffle(indices_id_shuffled)\n","  i_pos_val = []\n","  i_pos_trn = []\n","  for i in indices_id_shuffled:\n","    if i in i_pos_val:\n","      continue\n","    id = ids[i]\n","    ii_id = list(np.where(np.array(ids) == id)[0]) # find all indices corresponding to this table\n","    i_pos_val.extend(ii_id) # doesn't add new list -> extends the existing one\n","    # remove added ones from indices_id_shuffled so that we dont' find again the same table\n","    # indices_id_shuffled = [x for x in indices_id_shuffled if x not in ii_id]\n","    # stop \n","    if len(i_pos_val) >= n_pos_val:\n","      break\n","  diff_exp_vs_curr = len(i_pos_val) - n_pos_val\n","  # Training indices is the difference of all vs the validation ones\n","  i_pos_trn = [x for x in indices_id_shuffled if x not in i_pos_val]\n","  print(f\"Positive Validation PPT, wanted: {n_pos_val}, final: {len(i_pos_val)}\")\n","\n","common_ids = list(set(i_pos_trn).intersection(i_pos_val))\n","assert not common_ids # should be empty\n","\n","list_files_pos_val = [filename for i, filename in enumerate(list_files_pos) if i in i_pos_val]\n","list_files_pos_trn = [filename for i, filename in enumerate(list_files_pos) if i in i_pos_trn]\n","\n","print(\"Training: \", len(list_files_pos_trn))\n","print(\"Validation: \", len(list_files_pos_val))\n","\n","common_ids = list(set(list_files_pos_val).intersection(list_files_pos_trn))\n","print(list_files_pos_val)\n"]},{"cell_type":"markdown","metadata":{"id":"V9zkqtmK2n7j"},"source":["# Prepare custom dataset into the detectron2's standard format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9Tffb9VwHcY"},"outputs":[],"source":["img_dir_json = \"/gdrive/MyDrive/AnasPingPong/data/detection/positive_w_bbox\"\n","img_dir_jpeg = \"/gdrive/MyDrive/AnasPingPong/data/classification/train_validation/positive\"\n","\n","import glob\n","from detectron2.structures import BoxMode\n","import random\n","\n","def get_pingpong_dicts(d):\n","    print(img_dir_jpeg)\n","    print(img_dir_json)\n","    dataset_dicts = []\n"," \n","    if d == 'train':\n","      json_files_set = list_files_pos_trn\n","    else:\n","      json_files_set = list_files_pos_val\n","    \n","    count_missing = 0\n","    for json_file_name in json_files_set:\n","\n","      json_file = os.path.join(img_dir_json, json_file_name)\n","      with open(json_file) as f:\n","        v = json.load(f)\n","        record = {}\n","        height = v[\"imageHeight\"]\n","        width = v[\"imageWidth\"]\n","\n","        image_filename = os.path.join(img_dir_jpeg, v[\"imagePath\"])\n","\n","        if not os.path.exists(image_filename):\n","          count_missing += 1\n","          continue\n","        \n","        record[\"file_name\"] = image_filename\n","        record[\"image_id\"] = image_filename\n","        record[\"height\"] = height\n","        record[\"width\"] = width\n","\n","        annos = v[\"shapes\"]\n","        objs = []\n","        for anno in annos:\n","            points = anno['points']\n","            xs = [points[0][0], points[1][0]]\n","            ys = [points[0][1], points[1][1]]\n","            x1 = min(xs)\n","            x2 = max(xs)\n","            y1 = min(ys)\n","            y2 = max(ys)\n","\n","            x_poly = [x1, x2, x2, x1]\n","            y_poly = [y1, y1, y2, y2]\n","\n","            poly = [p for x in zip(x_poly, y_poly) for p in x]\n","            \n","\n","            obj = {\n","                \"bbox\": [x1, y1, x2, y2],\n","                \"bbox_mode\": BoxMode.XYXY_ABS,\n","               # \"segmentation\": [poly],\n","                \"category_id\": 0,\n","            }\n","            objs.append(obj)\n","        record[\"annotations\"] = objs\n","        dataset_dicts.append(record)\n","\n","    print(f'{d} dataset has {len(dataset_dicts)} samples')\n","    print(f'missing files: {count_missing}')\n","\n","    return dataset_dicts\n","\n","\n","DatasetCatalog.clear()\n","for d in [\"train\", \"val\"]:\n","    DatasetCatalog.register(\"ppt_\" + d, lambda d=d: get_pingpong_dicts(d))\n","    MetadataCatalog.get(\"ppt_\" + d).set(thing_classes=[\"ppt\"])\n","ppt_metadata = MetadataCatalog.get(\"ppt_train\")"]},{"cell_type":"markdown","metadata":{"id":"j_GjJOJhxwtJ"},"source":["#### Check dataloader \n","* Visualize some training images and corresponding bounding box "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h9y3HlBZxo1a"},"outputs":[],"source":["dataset_dicts = get_pingpong_dicts(\"train\")\n","for d in dataset_dicts[:10]:\n","    print(d[\"file_name\"])\n","    img = cv2.imread(d[\"file_name\"])\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=ppt_metadata, scale=2.0)\n","    out = visualizer.draw_dataset_dict(d)\n","    cv2_imshow(out.get_image()[:, :, ::-1])"]},{"cell_type":"markdown","metadata":{"id":"o7M-5Xifx5KR"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tx9e-Tmxy1J5"},"outputs":[],"source":["# check previous models\n","!ls \"/gdrive/MyDrive/AnasPingPong/models/object_detection/\""]},{"cell_type":"markdown","metadata":{"id":"aDnXfURd2_r4"},"source":["### Helper function for generating config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhayMg34pEbt"},"outputs":[],"source":["def get_train_cfg(output_dir, config_file_path, checkpoint_url, train_dataset_name, test_dataset_name, max_iter, chekpoint_period, eval_period, flag_resume):\n","  \n","    cfg = get_cfg()\n","    cfg.merge_from_file(model_zoo.get_config_file(config_file_path))\n","    if flag_resume:\n","       cfg.MODEL_WEIGHTS = checkpoint_url\n","    else:\n","      cfg.MODEL_WEIGHTS = model_zoo.get_checkpoint_url(checkpoint_url)\n","    cfg.DATASETS.TRAIN = (train_dataset_name,)\n","    cfg.DATASETS.TEST = (test_dataset_name,)\n","\n","    cfg.DATALOADER.NUM_WORKERS = 2\n","    cfg.SOLVER.IMS_PER_BATCH = 2\n","    cfg.SOLVER.BASE_LR = 0.00025\n","    cfg.SOLVER.MAX_ITER = max_iter\n","    cfg.SOLVER.CHECKPOINT_PERIOD = chekpoint_period\n","    cfg.SOLVER.STEPS = []\n","\n","    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n","    cfg.OUTPUT_DIR = output_dir\n","    cfg.TEST.EVAL_PERIOD = eval_period\n","\n","    return cfg"]},{"cell_type":"markdown","metadata":{"id":"eNGWtX-b2vKl"},"source":["#### Build Evaluator-Trainer class\n","* Allows evaluating performance on validation set at fixed intervals while training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4fSEUYw0cVV"},"outputs":[],"source":["from detectron2.engine import DefaultTrainer\n","from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","\n","class EvaluateTrainer(DefaultTrainer):\n","  @classmethod\n","  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n","    if output_folder is None:\n","        os.makedirs(os.path.join(cfg.OUTPUT_DIR, \"inference\"), exist_ok=True)\n","        output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n","        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n"]},{"cell_type":"markdown","metadata":{"id":"YnB31FJW3I_B"},"source":["## Start training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCI1lt0M69Kq"},"outputs":[],"source":["MODEL = \"faster_rcnn_R_101_FPN_3x.yaml\" # faster_rcnn_R_101_FPN_3x.yaml, faster_rcnn_X_101_32x8d_FPN_3x.yaml\n","output_dir_basis =\"/gdrive/MyDrive/AnasPingPong/models/object_detection/\"\n","timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M\")\n","output_foldername = \"_\".join([timestamp, MODEL.split(\".\")[0]])\n","output_dir = os.path.join(output_dir_basis, output_foldername)\n","print(output_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rSwdh5LywJQr"},"outputs":[],"source":["flag_resume=False\n","\n","cfg = get_train_cfg(\n","    output_dir=output_dir,\n","    config_file_path=os.path.join(\"COCO-Detection\", MODEL),\n","    checkpoint_url=os.path.join(\"COCO-Detection\", MODEL),\n","    train_dataset_name=\"ppt_train\",\n","    test_dataset_name =\"ppt_val\",\n","    max_iter=5_000,\n","    chekpoint_period=len(list_files_pos_trn)*4,\n","    eval_period=len(list_files_pos_trn)/2,\n","    flag_resume=flag_resume\n",")\n","# from pprint import pprint\n","# pprint(cfg)\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = EvaluateTrainer(cfg) # use DefaultTrainer if you don't need evaluation\n","trainer.resume_or_load(resume=flag_resume) \n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"W1LCwoVG3TgR"},"source":["## Continue training from a checkpoint\n","\n","* We just beed to load the weights from the last checkpoint and then increase MAX_ITER to the wanted number of training epochs \n","* Also set resume=True in trainer.resume_or_load(resume=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iUq-K7uUfz-O"},"outputs":[],"source":["# check previous models\n","!ls \"/gdrive/MyDrive/AnasPingPong/models/object_detection/\""]},{"cell_type":"code","source":["!ls \"/gdrive/MyDrive/AnasPingPong/models/object_detection/202112191542_faster_rcnn_R_101_FPN_3x\"\n"],"metadata":{"id":"_IIbxJ1nomku"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4PG9p5o7gf0"},"outputs":[],"source":["MODEL = \"faster_rcnn_R_101_FPN_3x.yaml\" # faster_rcnn_R_101_FPN_3x.yaml, faster_rcnn_X_101_32x8d_FPN_3x.yaml\n","output_dir_basis =\"/gdrive/MyDrive/AnasPingPong/models/object_detection/\"\n","timestamp = \"202112172206\"\n","output_foldername = \"_\".join([timestamp, MODEL.split(\".\")[0]])\n","output_dir = os.path.join(output_dir_basis, output_foldername)\n","checkpoint_of_interest = \"model_final.pth\" # \"model_final.pth\"\n","print(os.path.join(\"COCO-Detection\", MODEL))\n","print(os.path.join(output_dir, \"model_final.pth\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"voILYVbfyzCd"},"outputs":[],"source":["# output_dir -> Either use one defined in previous cell or select one from list of models\n","# MODEL -> similar to previous cell or select one from list of models\n","\n","flag_resume=True\n","\n","cfg = get_train_cfg(\n","    output_dir=output_dir,\n","    config_file_path=os.path.join(\"COCO-Detection\", MODEL),\n","    checkpoint_url=os.path.join(output_dir, \"model_final.pth\"),\n","    train_dataset_name=\"ppt_train\",\n","    test_dataset_name =\"ppt_val\",\n","    max_iter=20_000,\n","    chekpoint_period=len(list_files_pos_trn)*4,\n","    eval_period=len(list_files_pos_trn)/2,\n","    flag_resume=flag_resume\n","\n",")\n","\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","trainer = EvaluateTrainer(cfg)\n","trainer.resume_or_load(resume=flag_resume) \n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"V03fbyTY0fVS"},"source":["#  (TO FIX) Check training curves with Tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2op6KX4ecwo"},"outputs":[],"source":["# Look at training curves in tensorboard:\n","#!pip3 uninstall tensorboard -y\n","#!pip3 uninstall tensorflow -y\n","#!pip3 install --ignore-installed tf-nightly\n","%load_ext tensorboard\n","import tensorflow as tf\n","import datetime, os\n","\n","%tensorboard --logdir output"]},{"cell_type":"markdown","metadata":{"id":"9Fx_uv7JyDYd"},"source":["#Inference & evaluation using the trained model"]},{"cell_type":"markdown","metadata":{"id":"OvjTIXn1-Xv9"},"source":["### Create predictor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"leNZZg3vf2Z_"},"outputs":[],"source":["# check previous models\n","!ls \"/gdrive/MyDrive/AnasPingPong/models/object_detection/\"\n"]},{"cell_type":"code","source":["!ls \"/gdrive/MyDrive/AnasPingPong/models/object_detection/202112172206_faster_rcnn_R_101_FPN_3x\""],"metadata":{"id":"4hgvsFrmoj7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U2y_ZdQRwYLV"},"outputs":[],"source":["MODEL = \"faster_rcnn_R_101_FPN_3x.yaml\" # faster_rcnn_R_101_FPN_3x.yaml, faster_rcnn_X_101_32x8d_FPN_3x.yaml\n","output_dir_basis =\"/gdrive/MyDrive/AnasPingPong/models/object_detection/\"\n","timestamp = \"202112172206\" # eg \"202112170002\" or \"202112172206\"\n","output_foldername = \"_\".join([timestamp, MODEL.split(\".\")[0]])\n","output_dir = os.path.join(output_dir_basis, output_foldername)\n","print(output_dir)\n","checkpoint_of_interest = \"model_final.pth\" # \"model_final.pth\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snuEbTb9Kdrq"},"outputs":[],"source":["# output_dir -> Either use one define in previous cell or select one from list of models\n","# MODEL -> similar to previous cell or select one from list of models\n","\n","flag_resume=True # irrelevant\n","\n","cfg = get_train_cfg(\n","    output_dir=output_dir,\n","    config_file_path=os.path.join(\"COCO-Detection\", MODEL),\n","    checkpoint_url=os.path.join(output_dir,checkpoint_of_interest),\n","    train_dataset_name=\"ppt_train\", # irrelevant\n","    test_dataset_name =\"ppt_val\", # irrelevant\n","    max_iter=15_000, # irrelevant\n","    chekpoint_period=len(list_files_pos_trn)*5, # irrelevant\n","    eval_period=len(list_files_pos_trn), # irrelevant\n","    flag_resume=flag_resume # irrelevant\n","\n",")\n","\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, checkpoint_of_interest)  # path to the model we just trained\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n","predictor = DefaultPredictor(cfg)"]},{"cell_type":"markdown","metadata":{"id":"iSBMvyFvyLV8"},"source":["### Check model's predictions on validation data\n","\n","* *randomly* select several samples to visualize the prediction results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33if-whMyOY7"},"outputs":[],"source":["from detectron2.utils.visualizer import ColorMode\n","dataset_dicts = get_pingpong_dicts(\"valid\")\n","for d in dataset_dicts[:10]:\n","  im = cv2.imread(d[\"file_name\"])\n","  outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n","  print(outputs)\n","  v = Visualizer(im[:, :, ::-1],\n","                  metadata=ppt_metadata, \n","                  scale=2.0, \n","                  instance_mode=ColorMode.IMAGE   \n","  )\n","  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","  cv2_imshow(out.get_image()[:, :, ::-1])"]},{"cell_type":"markdown","metadata":{"id":"6Hj7WUKHdk6y"},"source":["# Check model's predictions on test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShbTqH5LdeoQ"},"outputs":[],"source":["import glob\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set a custom testing threshold\n","predictor = DefaultPredictor(cfg)\n","files = glob.glob(\"/gdrive/MyDrive/AnasPingPong/data/classification/test/negative/*\")\n","\n","# files_to_check = [\"563529_344025_20.jpeg\", \"563530_3440248_20.jpeg\", \"563528_344026_20.jpeg\"]\n","\n","for file in files:\n","  im = cv2.imread(file)\n","  outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n","  print(outputs)\n","  v = Visualizer(im[:, :, ::-1],\n","                  metadata=ppt_metadata, \n","                  scale=2.5, \n","                  instance_mode=ColorMode.IMAGE   \n","  )\n","  out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","  cv2_imshow(out.get_image()[:, :, ::-1])"]},{"cell_type":"markdown","metadata":{"id":"bd2YlNzOaES8"},"source":["# Model's performance evaluation using COCO's AP metric\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QpKPRkufaGAs"},"outputs":[],"source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","\n","def evaluate_on_validation(cfg, thr, data_validation_name):\n","  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = thr\n","  predictor = DefaultPredictor(cfg)\n","  evaluator = COCOEvaluator(data_validation_name, output_dir=\"./output\")\n","  val_loader = build_detection_test_loader(cfg, data_validation_name )\n","  result = inference_on_dataset(predictor.model, val_loader, evaluator)\n","  return result\n","\n","# Check for a threshold of 0.5\n","result = evaluate_on_validation(cfg, 0.5, \"ppt_val\")"]},{"cell_type":"markdown","metadata":{"id":"WzJQBG8tzepn"},"source":["## For selected model:  Extract AP metrics for different thesholds "]},{"cell_type":"code","source":["from pprint import pprint\n","pprint(cfg)"],"metadata":{"id":"yiJ97KYN91gd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMYe70Xql-pH"},"outputs":[],"source":["# Define thresholds (higher resolution for > 0.9)\n","thresholds_05_09 = np.arange(0.5, 0.99, 0.01)\n","thresholds_09_1 = np.arange(0.99, 1.0, 0.001)\n","thresholds_classification = list(np.concatenate([thresholds_05_09, thresholds_09_1]))\n","\n","# Estimate metrics for different thresholds\n","dict_metrics_per_thr = {}\n","for thr in thresholds_classification:\n","    print(f\"Evaluating performance of model for classification threshold :{thr}\")\n","    metrics = evaluate_on_validation(cfg, np.float(thr), \"ppt_val\")\n","    dict_metrics_per_thr[thr] = metrics\n","\n","# Save dictionary with metrics\n","filename_metrics_per_threshold = os.path.join(output_dir,str(checkpoint_of_interest.split(\".\")[0] + \"_metrics_diff_thresh.json\"))\n","with open(filename_metrics_per_threshold, 'w') as f_out:\n","    json.dump(dict_metrics_per_thr, f_out)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CnuT5ZyZ74wu"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"V2_APP_BoundingBox_Detectron2.ipynb","provenance":[{"file_id":"1pv1BVTH-Vg_3Tt-3kiTondOp-JZLDH22","timestamp":1639491526584}],"private_outputs":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}